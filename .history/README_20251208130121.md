# Watt about it RGPD

Repository focalisé sur la sécurité et la conformité RGPD pour le projet fil rouge MLOps.
Ce dépôt sert de base de travail au rôle Sécurité / RGPD.

## Objectifs
- Documenter le registre de traitements et la minimisation des données.
- Mettre en place les contrôles techniques: IAM, secrets, chiffrement, CI sécurité.
- Centraliser les preuves: captures anonymisées, journaux, matrices d’accès.
- Préparer la soutenance: runbook incident, model card, politiques.

## Démarrage
1. Compléter `docs/rgpd.md` avec votre cas d’usage et la base légale.
2. Renseigner `docs/data_inventory.csv` et `docs/access_matrix.csv`.
3. Activer les checks CI et secret scanning sur GitHub.
4. Ajouter vos captures anonymisées dans `docs/evidence/` (à créer).

## Rôles
- Security/RGPD Owner: vous
- Approvers requis: Security + Lead MLOps

## Workflows
- `ci-security.yml`: gitleaks secrets, Bandit SAST Python.
- Pré-commit recommandé avec detect-secrets.

## Liens utiles
- RGPD: registre, minimisation, rétention, DSR.
- Sécurité: IAM, Key Vault, HTTPS, logs, rotation clés.

## Ingestion des données
Première brique du pipeline MLOps : le script `etl/ingest_data.py` charge un CSV local, vérifie sa structure puis l'envoie vers le Data Lake cloud (AWS S3 par défaut) avec journalisation complète.

### Prérequis
- Python >= 3.9
- Dépendances : `pip install pandas boto3 python-dotenv`
- Variables d'environnement ou fichier `.env` (non versionné) contenant au minimum `DATA_LAKE_BUCKET` et, si besoin, `DATA_LAKE_PREFIX` et `AWS_REGION`.
- Accès à un bucket S3 et autorisations d'écriture.

### Données d'entrée
- Fichier d'échantillon versionné : `data/samples/sample_energy_consumption.csv`
- Les fichiers volumineux ou sensibles doivent rester dans `data/raw/` (ignoré par Git).

### Exécution
```
python -m etl.ingest_data --bucket <votre-bucket> --prefix watt-about-it/raw
```
- `--source` permet d'utiliser un autre CSV.
- `--dry-run` valide le fichier sans l'uploader (utile pour les tests locaux).

### Journaux et destination
- Chaque run génère `logs/ingestion_<run_id>.log` (ignoré par Git) contenant : source, validation, destination cloud et statut final.
- Les fichiers déposés suivent la structure `s3://<bucket>/<prefix>/<YYYY>/<MM>/<DD>/<nom_source>_<run_id>_<HHMMSS>.csv`, garantissant l'organisation par date et le versioning.
